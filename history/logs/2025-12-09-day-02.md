## Backend migration

- Migrated `app/main.py` from old project into new spec-driven structure.
- Verified it matches the Implementation Plan (section 2).
- Connected `chat` router only (no extra unused routes).

- Migrated <filename> from old project into new backend according to specification.

- Migrated `app/main.py` from old backend into new spec-driven backend (CORS + chat router only).

- Migrated `app/routers/chat.py` with RAG + Urdu + manual + auto personalization endpoints into the new backend.

- Migrated `app/services/rag_service.py` with RAG, Ask Section, Urdu translate, and manual personalization into new backend.
- Cleaned and aligned functions to SpecKit non-vibe structure.

- Migrated Qdrant, docs loader, auth client, chat schemas, and config from old backend into new spec-driven backend.

# Day 01 – Backend + Qdrant RAG Setup (NEW SpecKit Project)

## Context

- Old project: `C:\Users\Shoaib\Documents\ai-physical-humanoid-textbook`
- New SpecKit project: `D:\new-ai-physical-humanoid-textbook`
- Goal: Rebuild the RAG backend in a clean, non–vibe-coded way using SpecKit folder structure and logs.

---

## Steps Completed

### 1. Backend project structure

- Created new backend folder:

  - `apps/rag-backend/app`
  - `app/main.py`
  - `app/config.py`
  - `app/routers/chat.py`
  - `app/schemas/chat.py`
  - `app/services/{rag_service,qdrant_service,docs_service,auth_client,embeddings}.py`
  - `app/scripts/index_textbook.py`
  - Added `__init__.py` in:
    - `app/`
    - `app/routers/`
    - `app/schemas/`
    - `app/services/`
    - `app/scripts/`

### 2. Python environment + deps

- Created venv:

  - `python -m venv .venv`
  - `.\.venv\Scripts\activate`

- Installed dependencies:

  - `pip install -r requirements.txt`
  - Confirmed packages: `fastapi`, `uvicorn`, `pydantic`, `pydantic-settings`, `openai`, `qdrant-client`, `httpx`, `python-dotenv`, etc.

### 3. Settings & .env

- `Settings` class in `app/config.py` with:
  - `openai_api_key`
  - `qdrant_url`, `qdrant_api_key`, `qdrant_collection`
  - `backend_host`, `backend_port`
  - `backend_allowed_origins: List[str]`
  - `auth_server_url`
- Fixed `.env` error for `BACKEND_ALLOWED_ORIGINS` by either:
  - using default in code, or
  - using valid JSON list (e.g. `["http://localhost:3000"]`).

### 4. FastAPI app + CORS

- `app/main.py`:
  - Created `FastAPI` app with title: `"Physical AI & Humanoid Robotics — RAG Backend"`.
  - Configured CORS using `backend_allowed_origins`.
  - Included routers:
    - `health.router` (if present)
    - `chat.router`
  - Root endpoint `/` returns JSON with `message`, `backend_host`, `backend_port`, and `allowed_origins`.

### 5. Chat router + endpoints

- `app/routers/chat.py`:

  - `POST /chat` → full RAG answer using `answer_question`.
  - `POST /chat/ask-section` → uses `handle_ask_section`.
  - `POST /chat/translate/urdu` → uses `handle_translate_urdu`.
  - `POST /chat/personalize` → manual Chapter personalization (Level 8).
  - `POST /chat/personalize/auto` → auto personalization (Level 10) using:
    - `get_user_from_betterauth` to read session.
    - `extract_preferred_level` to get `"beginner" | "intermediate" | "advanced"`.
    - `load_doc_markdown(doc_id)` to load chapter.
    - OpenAI `gpt-4o-mini` to rewrite markdown.

### 6. RAG services

- `app/services/embeddings.py`:
  - Uses `OpenAI` embeddings:
    - Model: `text-embedding-3-small`
    - Dimension: `1536`
  - Function: `embed_texts(texts: List[str]) -> List[list[float]]`.

- `app/services/qdrant_service.py`:
  - `ensure_collection()` creates collection with:
    - `size = EMBEDDING_DIM`
    - `distance = COSINE`
  - `upsert_chunks(chunks)`:
    - Embeds all chunk texts.
    - Uses integer `id` for points to satisfy Qdrant’s point ID requirements.
    - Stores payload: `doc_id`, `chunk_index`, `text`.
  - `search(question, limit)`:
    - Embeds query.
    - Calls `query_points`.
    - Returns Python list of dicts with `text`, `doc_id`, `chunk_index`, `score`.

- `app/services/docs_service.py`:
  - Computes `PROJECT_ROOT` and `DOCS_ROOT = apps/book-frontend/docs`.
  - `load_doc_markdown(doc_id)` tries both `.md` and `.mdx`.

- `app/services/auth_client.py`:
  - `get_user_from_betterauth(request)` → calls `AUTH_BASE_URL + "/user"` with cookies.
  - `extract_preferred_level(user)` → normalizes `preferredLevel` to `beginner | intermediate | advanced`.

- `app/services/rag_service.py`:
  - `answer_question`:
    - Calls `search`.
    - Builds context-aware prompt.
    - Calls `client.chat.completions.create` with `gpt-4.1-mini`.
    - Returns `ChatResponse` with `answer` + `sources`.
  - `handle_translate_urdu`:
    - Loads markdown by `doc_id`.
    - Uses system prompt to translate to Urdu while preserving markdown.
  - `handle_personalize`:
    - Loads markdown.
    - Chooses instruction from level (`beginner | intermediate | advanced`).
    - Calls OpenAI to rewrite chapter with preserved markdown structure.

### 7. Qdrant indexing

- Copied docs from old project:

  - `C:\Users\Shoaib\Documents\ai-physical-humanoid-textbook\apps\book-frontend\docs`
  - → `D:\new-ai-physical-humanoid-textbook\apps\book-frontend\docs`

- Ran indexing script:

  - `python -m app.scripts.index_textbook`
  - Loaded 9 chapters from `foundations/*`.
  - Total: **59 chunks indexed** into Qdrant.
  - Final output: `Indexing 59 chunks into Qdrant... Done.`

### 8. Validation via Swagger UI

- Started backend:

  - `uvicorn app.main:app --reload --port 8000`

- Opened Swagger at `http://127.0.0.1:8000/docs`.
- Called `POST /chat` with:

  ```json
  { "question": "What is Physical AI and why are humanoid robots important?" }
